---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  comment = "#>"
)
```

# Análise de dados - Messias

Banco de dados referente à produção da cana-de-açúcar, anos de 2016 a 2018, e atributos do solo.

### Carregando pacotes
```{r}
library(tidyverse)
library(sp)
library(vegan)
library(readxl)
library(gstat)
library(plotly)
library(nortest)
theme_set(theme_bw())
```

### Arrumando o banco de dados no excel.

```{r}
# list_files <- list.files("data-raw", full.names = TRUE)
# 
# my_read_xl <- function(path){
#   read_excel(path) %>% 
#     mutate(
#   ano = str_extract(path,"[0-9]+")
#   ) %>% relocate(ano)
# }
# my_read_xl(list_files[3])
# dff <- map_df(list_files,my_read_xl)
# write_rds(dff, "data/sugarcane-soil-production.rds")
```

### Lendo o banco em rds

```{r}
data_set <- read_rds("data/sugarcane-soil-production.rds")
contorno <- read.table("data/coordenadas-contorno.txt",sep=",",h=TRUE)
p <- Polygon(contorno)
ps <- Polygons(list(p),1)
contorno_ps <- SpatialPolygons(list(ps))
def_pol <- function(x, y, pol){
  as.logical(sp::point.in.polygon(point.x = x,
                                  point.y = y,
                                  pol.x = pol[,1],
                                  pol.y = pol[,2]))
}
```

```{r}
x<-data_set$x
y<-data_set$y
dis <- 0.005 #Distância entre pontos
grid <- expand.grid(X=seq(min(x),max(x),dis), Y=seq(min(y),max(y),dis)) %>% 
    mutate(flag = def_pol(X,Y,contorno)) %>%  
  filter(flag) %>% select(-flag)
gridded(grid) = ~ X + Y
plot(grid) 
points(x,y,col="red",pch=4)
```

### Conhecendo o Banco de dados

```{r}
data_set %>% 
  filter(ano == 2016) %>% 
  ggplot(aes(x=x, y=y)) +
  geom_point()
# ggplotly(plot_graph)
```

```{r}
glimpse(data_set)
```


# PASSO 1
definir o ano e a variável

### Separa o banco de dados por ano e por variáveis
```{r}
ano_analise <- 2018
variavel <- "tch_real"
data_set_aux <- data_set %>% 
  filter(ano == ano_analise) %>% 
  select(x,y,variavel)
names(data_set_aux) <- c("x","y","z")
glimpse(data_set_aux)
```

### Calcular a média da variável por ponto
```{r}
data_set_aux <- data_set_aux %>% 
  group_by(x,y) %>% 
  summarise(
    z = mean(z,na.rm = TRUE)
  )
```

### Análise exoploratória

```{r}
data_set_aux %>% 
  pull(z) %>% 
  summary()
```
```{r}
data_set_aux %>% 
  ggplot(aes(y=z)) +
  geom_boxplot(fill="gray") +
  xlim(-1,1) +
  labs(y = variavel)
```
```{r}
data_set_aux %>% 
  ggplot(aes(x=z)) +
  geom_histogram(fill="gray",color="black",
                 bins = 10) +
  labs(x = variavel)
```
Testes de normalidade
```{r}
y <- data_set_aux %>% pull(z)
shapiro.test(y)
cvm.test(y)
lillie.test(y)
ad.test(y)
```


```{r}
data_set_aux %>% 
  ggplot(aes(x=x,y=y,color=z)) +
  geom_point() +
  labs(color = variavel)
```

### Análise geoestatística

Criar o arquivo para análise

```{r}
coordinates(data_set_aux) = ~ x + y  
form <- z ~ 1 # fórmula da função variogram
```

## PASSO 2

Construir o semivariograma experimental

```{r}
vari_exp <- variogram(form, data = data_set_aux,
                      cressie = FALSE,
                      cutoff = 0.20, # distância máxima do semivariograma
                      width = .008) # distancia entre pontos
vari_exp  %>%  
 ggplot(aes(x=dist, y=gamma)) +
 geom_point() +
 labs(x="lag (º)",
      y=expression(paste(gamma,"(h)")))
```


#### Escolha do melhor modelo
```{r}
patamar=400
alcance=0.05
epepita=0
modelo_1 <- fit.variogram(vari_exp,vgm(patamar,"Sph",alcance,epepita))
modelo_2 <- fit.variogram(vari_exp,vgm(patamar,"Exp",alcance,epepita))
modelo_3 <- fit.variogram(vari_exp,vgm(patamar,"Gau",alcance,epepita))
sqr.f1<-round(attr(modelo_1, "SSErr"),4); c01<-round(modelo_1$psill[[1]],4); c0_c11<-round(sum(modelo_1$psill),4);a1<-round(modelo_1$range[[2]],2)
sqr.f2<-round(attr(modelo_2, "SSErr"),4); c02<-round(modelo_2$psill[[1]],4); c0_c12<-round(sum(modelo_2$psill),4);a2<-round(3*modelo_2$range[[2]],2)
sqr.f3<-round(attr(modelo_3, "SSErr"),4); c03<-round(modelo_3$psill[[1]],4); c0_c13<-round(sum(modelo_3$psill),4);a3<-round(modelo_3$range[[2]]*(3^.5),2)

df_aux <- vari_exp %>% 
  mutate(
    gamma_m1 = ifelse(dist <= a1, c01 + (c0_c11-c01)*(3/2*(dist/a1)-1/2*(dist/a1)^3),c0_c11),
    gamma_m2 = c02 + (c0_c12-c02)*(1-exp(-3*(dist/a2))),
    gamma_m3 = c03 + (c0_c13-c03)*(1-exp(-3*(dist/a3)^2)),
    residuo_total = (gamma-mean(gamma))^2,
    residuo_mod_1 = (gamma - gamma_m1)^2,
    residuo_mod_2 = (gamma - gamma_m2)^2,
    residuo_mod_3 = (gamma - gamma_m3)^2
  ) %>% 
  summarise(
    r2_1=(sum(residuo_total) - sum(residuo_mod_1))/sum(residuo_total), 
    r2_2=(sum(residuo_total) - sum(residuo_mod_2))/sum(residuo_total), 
    r2_3=(sum(residuo_total) - sum(residuo_mod_3))/sum(residuo_total), 
  )
r21<-as.vector(round(df_aux[1],4))
r22<-as.vector(round(df_aux[2],4))
r23<-as.vector(round(df_aux[3],4))

plot(vari_exp,model=modelo_1, col=1,pl=F,pch=16,cex=1.2,cex.main=7,ylab=list("Semivariância",cex=1.3),xlab=list("Distância de Separação h (m)",cex=1.3),main =paste("Esf(C0= ",c01,"; C0+C1= ", c0_c11, "; a= ", a1,"; r2 = ", r21,")",sep=""))
plot(vari_exp,model=modelo_2, col=1,pl=F,pch=16,cex=1.2,cex.main=7,ylab=list("Semivariância",cex=1.3),xlab=list("Distância de Separação h (m)",cex=1.3),main =paste("Exp(C0= ",c02,"; C0+C1= ", c0_c12, "; a= ", a2,"; r2 = ", r22,")",sep=""))
plot(vari_exp,model=modelo_3, col=1,pl=F,pch=16,cex=1.2,cex.main=7,ylab=list("Semivariância",cex=1.3),xlab=list("Distância de Separação h (m)",cex=1.3),main =paste("Gau(C0= ",c03,"; C0+C1= ", c0_c13, "; a= ", a3,"; r2 = ", r23,")",sep=""))
```

## Validação Cruzada



```{r}
conjunto_validacao <- data_set_aux %>% 
  as_tibble() %>% 
  sample_n(300)
coordinates(conjunto_validacao) = ~x + y
modelos<-list(modelo_1,modelo_2,modelo_3)
for(j in 1:3){
	est<-0
	# vari<-as.character(form)[2]
	for(i in 1:nrow(conjunto_validacao)){
		valid <- krige(formula=form, conjunto_validacao[-i,], conjunto_validacao, model=modelos[[j]])
		est[i]<-valid$var1.pred[i]
	}
	obs<-as.data.frame(conjunto_validacao)[,3] 
	RMSE<-round((sum((obs-est)^2)/length(obs))^.5,3)
	mod<-lm(obs~est)
	b<-round(mod$coefficients[2],3)
	se<-round(summary(mod)$coefficients[4],3)
	r2<-round(summary(mod)$r.squared,3) 
	a<-round(mod$coefficients[1],3)
	plot(est,obs,xlab="Estimado", ylab="Observado",pch=j,col="blue",
		main=paste("Modelo = ",modelos[[j]][2,1],"; Coef. Reg. = ", b, " (SE = ",se, ", r2 = ", r2,")\ny intersept = ",a,"RMSE = ",RMSE ))
	abline(lm(obs~est));
	abline(0,1,lty=3)
}

```


## PASSO 3 

selecionar o melhor modelo
Modelar o semivariograma
```{r}
modelo <- modelo_1 ## sempre modificar
plot(vari_exp,model=modelo, col=1,pl=F,pch=16)
```




## PASSO 4 

### Krigragem ordinária (KO)

Utilizando o algorítmo de KO, vamos estimar xco2 nos locais não amostrados.


    
```{r}
ko_variavel <- krige(formula=form, data_set_aux, grid, model=modelo, 
    block=c(0,0),
    nsim=0,
    na.action=na.pass,
    debug.level=-1,  
    )
```

Mapa de padrão espacial

```{r}
mapa <- as.tibble(ko_variavel) %>% 
  ggplot(aes(x=X, y=Y)) + 
  geom_tile(aes(fill = var1.pred)) +
  # scale_fill_gradient(low = "yellow", high = "blue") + 
  scale_fill_viridis_c() +
  coord_equal() + 
  labs(fill=variavel,
       x="Longitude",
       y="Latitude")
mapa
ggsave(paste0("mapas/krigagem-",variavel,"-",ano_analise,".png"))


# Salvando o arquivo krigado


df <- ko_variavel %>% 
  as.tibble() %>% 
  mutate(var1.var = sqrt(var1.var)) %>% 
  rename(
    !!variavel := var1.pred,
    !!paste0(variavel,"_sd") := var1.var,
  )
write_rds(df,paste0("saida/",variavel,"-",ano_analise,".rds"))
```

